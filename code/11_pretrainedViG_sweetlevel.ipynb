{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # 대화형 모드\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022.06.17-Changed for building ViG model\n",
    "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
    "# modified from https://github.com/facebookresearch/mae/blob/main/util/pos_embed.py\n",
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "# All rights reserved.\n",
    "\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "# --------------------------------------------------------\n",
    "# Position embedding utils\n",
    "# --------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# relative position embedding\n",
    "# References: https://arxiv.org/abs/2009.13658\n",
    "# --------------------------------------------------------\n",
    "def get_2d_relative_pos_embed(embed_dim, grid_size):\n",
    "    \"\"\"\n",
    "    grid_size: int of the grid height and width\n",
    "    return:\n",
    "    pos_embed: [grid_size*grid_size, grid_size*grid_size]\n",
    "    \"\"\"\n",
    "    pos_embed = get_2d_sincos_pos_embed(embed_dim, grid_size)\n",
    "    relative_pos = 2 * np.matmul(pos_embed, pos_embed.transpose()) / pos_embed.shape[1]\n",
    "    return relative_pos\n",
    "\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2D sine-cosine position embedding\n",
    "# References:\n",
    "# Transformer: https://github.com/tensorflow/models/blob/master/official/nlp/transformer/model_utils.py\n",
    "# MoCo v3: https://github.com/facebookresearch/moco-v3\n",
    "# --------------------------------------------------------\n",
    "def get_2d_sincos_pos_embed(embed_dim, grid_size, cls_token=False):\n",
    "    \"\"\"\n",
    "    grid_size: int of the grid height and width\n",
    "    return:\n",
    "    pos_embed: [grid_size*grid_size, embed_dim] or [1+grid_size*grid_size, embed_dim] (w/ or w/o cls_token)\n",
    "    \"\"\"\n",
    "    grid_h = np.arange(grid_size, dtype=np.float32)\n",
    "    grid_w = np.arange(grid_size, dtype=np.float32)\n",
    "    grid = np.meshgrid(grid_w, grid_h)  # here w goes first\n",
    "    grid = np.stack(grid, axis=0)\n",
    "\n",
    "    grid = grid.reshape([2, 1, grid_size, grid_size])\n",
    "    pos_embed = get_2d_sincos_pos_embed_from_grid(embed_dim, grid)\n",
    "    if cls_token:\n",
    "        pos_embed = np.concatenate([np.zeros([1, embed_dim]), pos_embed], axis=0)\n",
    "    return pos_embed\n",
    "\n",
    "\n",
    "def get_2d_sincos_pos_embed_from_grid(embed_dim, grid):\n",
    "    assert embed_dim % 2 == 0\n",
    "\n",
    "    # use half of dimensions to encode grid_h\n",
    "    emb_h = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[0])  # (H*W, D/2)\n",
    "    emb_w = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[1])  # (H*W, D/2)\n",
    "\n",
    "    emb = np.concatenate([emb_h, emb_w], axis=1) # (H*W, D)\n",
    "    return emb\n",
    "\n",
    "\n",
    "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
    "    \"\"\"\n",
    "    embed_dim: output dimension for each position\n",
    "    pos: a list of positions to be encoded: size (M,)\n",
    "    out: (M, D)\n",
    "    \"\"\"\n",
    "    assert embed_dim % 2 == 0\n",
    "    omega = np.arange(embed_dim // 2, dtype=np.float)\n",
    "    omega /= embed_dim / 2.\n",
    "    omega = 1. / 10000**omega  # (D/2,)\n",
    "\n",
    "    pos = pos.reshape(-1)  # (M,)\n",
    "    out = np.einsum('m,d->md', pos, omega)  # (M, D/2), outer product\n",
    "\n",
    "    emb_sin = np.sin(out) # (M, D/2)\n",
    "    emb_cos = np.cos(out) # (M, D/2)\n",
    "\n",
    "    emb = np.concatenate([emb_sin, emb_cos], axis=1)  # (M, D)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022.06.17-Changed for building ViG model\n",
    "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def pairwise_distance(x):\n",
    "    \"\"\"\n",
    "    Compute pairwise distance of a point cloud.\n",
    "    Args:\n",
    "        x: tensor (batch_size, num_points, num_dims)\n",
    "    Returns:\n",
    "        pairwise distance: (batch_size, num_points, num_points)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        x_inner = -2*torch.matmul(x, x.transpose(2, 1))\n",
    "        x_square = torch.sum(torch.mul(x, x), dim=-1, keepdim=True)\n",
    "        return x_square + x_inner + x_square.transpose(2, 1)\n",
    "\n",
    "\n",
    "def part_pairwise_distance(x, start_idx=0, end_idx=1):\n",
    "    \"\"\"\n",
    "    Compute pairwise distance of a point cloud.\n",
    "    Args:\n",
    "        x: tensor (batch_size, num_points, num_dims)\n",
    "    Returns:\n",
    "        pairwise distance: (batch_size, num_points, num_points)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        x_part = x[:, start_idx:end_idx]\n",
    "        x_square_part = torch.sum(torch.mul(x_part, x_part), dim=-1, keepdim=True)\n",
    "        x_inner = -2*torch.matmul(x_part, x.transpose(2, 1))\n",
    "        x_square = torch.sum(torch.mul(x, x), dim=-1, keepdim=True)\n",
    "        return x_square_part + x_inner + x_square.transpose(2, 1)\n",
    "\n",
    "\n",
    "def xy_pairwise_distance(x, y):\n",
    "    \"\"\"\n",
    "    Compute pairwise distance of a point cloud.\n",
    "    Args:\n",
    "        x: tensor (batch_size, num_points, num_dims)\n",
    "    Returns:\n",
    "        pairwise distance: (batch_size, num_points, num_points)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        xy_inner = -2*torch.matmul(x, y.transpose(2, 1))\n",
    "        x_square = torch.sum(torch.mul(x, x), dim=-1, keepdim=True)\n",
    "        y_square = torch.sum(torch.mul(y, y), dim=-1, keepdim=True)\n",
    "        return x_square + xy_inner + y_square.transpose(2, 1)\n",
    "\n",
    "\n",
    "def dense_knn_matrix(x, k=16, relative_pos=None):\n",
    "    \"\"\"Get KNN based on the pairwise distance.\n",
    "    Args:\n",
    "        x: (batch_size, num_dims, num_points, 1)\n",
    "        k: int\n",
    "    Returns:\n",
    "        nearest neighbors: (batch_size, num_points, k) (batch_size, num_points, k)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        x = x.transpose(2, 1).squeeze(-1)\n",
    "        batch_size, n_points, n_dims = x.shape\n",
    "        ### memory efficient implementation ###\n",
    "        n_part = 10000\n",
    "        if n_points > n_part:\n",
    "            nn_idx_list = []\n",
    "            groups = math.ceil(n_points / n_part)\n",
    "            for i in range(groups):\n",
    "                start_idx = n_part * i\n",
    "                end_idx = min(n_points, n_part * (i + 1))\n",
    "                dist = part_pairwise_distance(x.detach(), start_idx, end_idx)\n",
    "                if relative_pos is not None:\n",
    "                    dist += relative_pos[:, start_idx:end_idx]\n",
    "                _, nn_idx_part = torch.topk(-dist, k=k)\n",
    "                nn_idx_list += [nn_idx_part]\n",
    "            nn_idx = torch.cat(nn_idx_list, dim=1)\n",
    "        else:\n",
    "            dist = pairwise_distance(x.detach())\n",
    "            if relative_pos is not None:\n",
    "                dist += relative_pos\n",
    "            _, nn_idx = torch.topk(-dist, k=k) # b, n, k\n",
    "        ######\n",
    "        center_idx = torch.arange(0, n_points, device=x.device).repeat(batch_size, k, 1).transpose(2, 1)\n",
    "    return torch.stack((nn_idx, center_idx), dim=0)\n",
    "\n",
    "\n",
    "def xy_dense_knn_matrix(x, y, k=16, relative_pos=None):\n",
    "    \"\"\"Get KNN based on the pairwise distance.\n",
    "    Args:\n",
    "        x: (batch_size, num_dims, num_points, 1)\n",
    "        k: int\n",
    "    Returns:\n",
    "        nearest neighbors: (batch_size, num_points, k) (batch_size, num_points, k)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        x = x.transpose(2, 1).squeeze(-1)\n",
    "        y = y.transpose(2, 1).squeeze(-1)\n",
    "        batch_size, n_points, n_dims = x.shape\n",
    "        dist = xy_pairwise_distance(x.detach(), y.detach())\n",
    "        if relative_pos is not None:\n",
    "            dist += relative_pos\n",
    "        _, nn_idx = torch.topk(-dist, k=k)\n",
    "        center_idx = torch.arange(0, n_points, device=x.device).repeat(batch_size, k, 1).transpose(2, 1)\n",
    "    return torch.stack((nn_idx, center_idx), dim=0)\n",
    "\n",
    "\n",
    "class DenseDilated(nn.Module):\n",
    "    \"\"\"\n",
    "    Find dilated neighbor from neighbor list\n",
    "\n",
    "    edge_index: (2, batch_size, num_points, k)\n",
    "    \"\"\"\n",
    "    def __init__(self, k=9, dilation=1, stochastic=False, epsilon=0.0):\n",
    "        super(DenseDilated, self).__init__()\n",
    "        self.dilation = dilation\n",
    "        self.stochastic = stochastic\n",
    "        self.epsilon = epsilon\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, edge_index):\n",
    "        if self.stochastic:\n",
    "            if torch.rand(1) < self.epsilon and self.training:\n",
    "                num = self.k * self.dilation\n",
    "                randnum = torch.randperm(num)[:self.k]\n",
    "                edge_index = edge_index[:, :, :, randnum]\n",
    "            else:\n",
    "                edge_index = edge_index[:, :, :, ::self.dilation]\n",
    "        else:\n",
    "            edge_index = edge_index[:, :, :, ::self.dilation]\n",
    "        return edge_index\n",
    "\n",
    "\n",
    "class DenseDilatedKnnGraph(nn.Module):\n",
    "    \"\"\"\n",
    "    Find the neighbors' indices based on dilated knn\n",
    "    \"\"\"\n",
    "    def __init__(self, k=9, dilation=1, stochastic=False, epsilon=0.0):\n",
    "        super(DenseDilatedKnnGraph, self).__init__()\n",
    "        self.dilation = dilation\n",
    "        self.stochastic = stochastic\n",
    "        self.epsilon = epsilon\n",
    "        self.k = k\n",
    "        self._dilated = DenseDilated(k, dilation, stochastic, epsilon)\n",
    "\n",
    "    def forward(self, x, y=None, relative_pos=None):\n",
    "        if y is not None:\n",
    "            #### normalize\n",
    "            x = F.normalize(x, p=2.0, dim=1)\n",
    "            y = F.normalize(y, p=2.0, dim=1)\n",
    "            ####\n",
    "            edge_index = xy_dense_knn_matrix(x, y, self.k * self.dilation, relative_pos)\n",
    "        else:\n",
    "            #### normalize\n",
    "            x = F.normalize(x, p=2.0, dim=1)\n",
    "            ####\n",
    "            edge_index = dense_knn_matrix(x, self.k * self.dilation, relative_pos)\n",
    "        return self._dilated(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022.06.17-Changed for building ViG model\n",
    "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, Conv2d\n",
    "\n",
    "\n",
    "##############################\n",
    "#    Basic layers\n",
    "##############################\n",
    "def act_layer(act, inplace=False, neg_slope=0.2, n_prelu=1):\n",
    "    # activation layer\n",
    "\n",
    "    act = act.lower()\n",
    "    if act == 'relu':\n",
    "        layer = nn.ReLU(inplace)\n",
    "    elif act == 'leakyrelu':\n",
    "        layer = nn.LeakyReLU(neg_slope, inplace)\n",
    "    elif act == 'prelu':\n",
    "        layer = nn.PReLU(num_parameters=n_prelu, init=neg_slope)\n",
    "    elif act == 'gelu':\n",
    "        layer = nn.GELU()\n",
    "    elif act == 'hswish':\n",
    "        layer = nn.Hardswish(inplace)\n",
    "    else:\n",
    "        raise NotImplementedError('activation layer [%s] is not found' % act)\n",
    "    return layer\n",
    "\n",
    "\n",
    "def norm_layer(norm, nc):\n",
    "    # normalization layer 2d\n",
    "    norm = norm.lower()\n",
    "    if norm == 'batch':\n",
    "        layer = nn.BatchNorm2d(nc, affine=True)\n",
    "    elif norm == 'instance':\n",
    "        layer = nn.InstanceNorm2d(nc, affine=False)\n",
    "    else:\n",
    "        raise NotImplementedError('normalization layer [%s] is not found' % norm)\n",
    "    return layer\n",
    "\n",
    "\n",
    "class MLP(Seq):\n",
    "    def __init__(self, channels, act='relu', norm=None, bias=True):\n",
    "        m = []\n",
    "        for i in range(1, len(channels)):\n",
    "            m.append(Lin(channels[i - 1], channels[i], bias))\n",
    "            if act is not None and act.lower() != 'none':\n",
    "                m.append(act_layer(act))\n",
    "            if norm is not None and norm.lower() != 'none':\n",
    "                m.append(norm_layer(norm, channels[-1]))\n",
    "        super(MLP, self).__init__(*m)\n",
    "\n",
    "\n",
    "class BasicConv(Seq):\n",
    "    def __init__(self, channels, act='relu', norm=None, bias=True, drop=0.):\n",
    "        m = []\n",
    "        for i in range(1, len(channels)):\n",
    "            m.append(Conv2d(channels[i - 1], channels[i], 1, bias=bias, groups=4))\n",
    "            if norm is not None and norm.lower() != 'none':\n",
    "                m.append(norm_layer(norm, channels[-1]))\n",
    "            if act is not None and act.lower() != 'none':\n",
    "                m.append(act_layer(act))\n",
    "            if drop > 0:\n",
    "                m.append(nn.Dropout2d(drop))\n",
    "\n",
    "        super(BasicConv, self).__init__(*m)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.InstanceNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def batched_index_select(x, idx):\n",
    "    r\"\"\"fetches neighbors features from a given neighbor idx\n",
    "\n",
    "    Args:\n",
    "        x (Tensor): input feature Tensor\n",
    "                :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times C \\times N \\times 1}`.\n",
    "        idx (Tensor): edge_idx\n",
    "                :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times N \\times l}`.\n",
    "    Returns:\n",
    "        Tensor: output neighbors features\n",
    "            :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times C \\times N \\times k}`.\n",
    "    \"\"\"\n",
    "    batch_size, num_dims, num_vertices_reduced = x.shape[:3]\n",
    "    _, num_vertices, k = idx.shape\n",
    "    idx_base = torch.arange(0, batch_size, device=idx.device).view(-1, 1, 1) * num_vertices_reduced\n",
    "    idx = idx + idx_base\n",
    "    idx = idx.contiguous().view(-1)\n",
    "\n",
    "    x = x.transpose(2, 1)\n",
    "    feature = x.contiguous().view(batch_size * num_vertices_reduced, -1)[idx, :]\n",
    "    feature = feature.view(batch_size, num_vertices, k, num_dims).permute(0, 3, 1, 2).contiguous()\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022.06.17-Changed for building ViG model\n",
    "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "# from .torch_nn import BasicConv, batched_index_select, act_layer\n",
    "# from .torch_edge import DenseDilatedKnnGraph\n",
    "# from .pos_embed import get_2d_relative_pos_embed\n",
    "import torch.nn.functional as F\n",
    "from timm.models.layers import DropPath\n",
    "\n",
    "\n",
    "class MRConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Max-Relative Graph Convolution (Paper: https://arxiv.org/abs/1904.03751) for dense data type\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, act='relu', norm=None, bias=True):\n",
    "        super(MRConv2d, self).__init__()\n",
    "        self.nn = BasicConv([in_channels*2, out_channels], act, norm, bias)\n",
    "\n",
    "    def forward(self, x, edge_index, y=None):\n",
    "        x_i = batched_index_select(x, edge_index[1])\n",
    "        if y is not None:\n",
    "            x_j = batched_index_select(y, edge_index[0])\n",
    "        else:\n",
    "            x_j = batched_index_select(x, edge_index[0])\n",
    "        x_j, _ = torch.max(x_j - x_i, -1, keepdim=True)\n",
    "        b, c, n, _ = x.shape\n",
    "        x = torch.cat([x.unsqueeze(2), x_j.unsqueeze(2)], dim=2).reshape(b, 2 * c, n, _)\n",
    "        return self.nn(x)\n",
    "\n",
    "\n",
    "class EdgeConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Edge convolution layer (with activation, batch normalization) for dense data type\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, act='relu', norm=None, bias=True):\n",
    "        super(EdgeConv2d, self).__init__()\n",
    "        self.nn = BasicConv([in_channels * 2, out_channels], act, norm, bias)\n",
    "\n",
    "    def forward(self, x, edge_index, y=None):\n",
    "        x_i = batched_index_select(x, edge_index[1])\n",
    "        if y is not None:\n",
    "            x_j = batched_index_select(y, edge_index[0])\n",
    "        else:\n",
    "            x_j = batched_index_select(x, edge_index[0])\n",
    "        max_value, _ = torch.max(self.nn(torch.cat([x_i, x_j - x_i], dim=1)), -1, keepdim=True)\n",
    "        return max_value\n",
    "\n",
    "\n",
    "class GraphSAGE(nn.Module):\n",
    "    \"\"\"\n",
    "    GraphSAGE Graph Convolution (Paper: https://arxiv.org/abs/1706.02216) for dense data type\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, act='relu', norm=None, bias=True):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.nn1 = BasicConv([in_channels, in_channels], act, norm, bias)\n",
    "        self.nn2 = BasicConv([in_channels*2, out_channels], act, norm, bias)\n",
    "\n",
    "    def forward(self, x, edge_index, y=None):\n",
    "        if y is not None:\n",
    "            x_j = batched_index_select(y, edge_index[0])\n",
    "        else:\n",
    "            x_j = batched_index_select(x, edge_index[0])\n",
    "        x_j, _ = torch.max(self.nn1(x_j), -1, keepdim=True)\n",
    "        return self.nn2(torch.cat([x, x_j], dim=1))\n",
    "\n",
    "\n",
    "class GINConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    GIN Graph Convolution (Paper: https://arxiv.org/abs/1810.00826) for dense data type\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, act='relu', norm=None, bias=True):\n",
    "        super(GINConv2d, self).__init__()\n",
    "        self.nn = BasicConv([in_channels, out_channels], act, norm, bias)\n",
    "        eps_init = 0.0\n",
    "        self.eps = nn.Parameter(torch.Tensor([eps_init]))\n",
    "\n",
    "    def forward(self, x, edge_index, y=None):\n",
    "        if y is not None:\n",
    "            x_j = batched_index_select(y, edge_index[0])\n",
    "        else:\n",
    "            x_j = batched_index_select(x, edge_index[0])\n",
    "        x_j = torch.sum(x_j, -1, keepdim=True)\n",
    "        return self.nn((1 + self.eps) * x + x_j)\n",
    "\n",
    "\n",
    "class GraphConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Static graph convolution layer\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, conv='edge', act='relu', norm=None, bias=True):\n",
    "        super(GraphConv2d, self).__init__()\n",
    "        if conv == 'edge':\n",
    "            self.gconv = EdgeConv2d(in_channels, out_channels, act, norm, bias)\n",
    "        elif conv == 'mr':\n",
    "            self.gconv = MRConv2d(in_channels, out_channels, act, norm, bias)\n",
    "        elif conv == 'sage':\n",
    "            self.gconv = GraphSAGE(in_channels, out_channels, act, norm, bias)\n",
    "        elif conv == 'gin':\n",
    "            self.gconv = GINConv2d(in_channels, out_channels, act, norm, bias)\n",
    "        else:\n",
    "            raise NotImplementedError('conv:{} is not supported'.format(conv))\n",
    "\n",
    "    def forward(self, x, edge_index, y=None):\n",
    "        return self.gconv(x, edge_index, y)\n",
    "\n",
    "\n",
    "class DyGraphConv2d(GraphConv2d):\n",
    "    \"\"\"\n",
    "    Dynamic graph convolution layer\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=9, dilation=1, conv='edge', act='relu',\n",
    "                 norm=None, bias=True, stochastic=False, epsilon=0.0, r=1):\n",
    "        super(DyGraphConv2d, self).__init__(in_channels, out_channels, conv, act, norm, bias)\n",
    "        self.k = kernel_size\n",
    "        self.d = dilation\n",
    "        self.r = r\n",
    "        self.dilated_knn_graph = DenseDilatedKnnGraph(kernel_size, dilation, stochastic, epsilon)\n",
    "\n",
    "    def forward(self, x, relative_pos=None):\n",
    "        B, C, H, W = x.shape\n",
    "        y = None\n",
    "        if self.r > 1:\n",
    "            y = F.avg_pool2d(x, self.r, self.r)\n",
    "            y = y.reshape(B, C, -1, 1).contiguous()            \n",
    "        x = x.reshape(B, C, -1, 1).contiguous()\n",
    "        edge_index = self.dilated_knn_graph(x, y, relative_pos)\n",
    "        x = super(DyGraphConv2d, self).forward(x, edge_index, y)\n",
    "        return x.reshape(B, -1, H, W).contiguous()\n",
    "\n",
    "\n",
    "class Grapher(nn.Module):\n",
    "    \"\"\"\n",
    "    Grapher module with graph convolution and fc layers\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, kernel_size=9, dilation=1, conv='edge', act='relu', norm=None,\n",
    "                 bias=True,  stochastic=False, epsilon=0.0, r=1, n=196, drop_path=0.0, relative_pos=False, LPE=False):\n",
    "        super(Grapher, self).__init__()\n",
    "        self.channels = in_channels\n",
    "        self.n = n\n",
    "        self.r = r\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "        )\n",
    "        self.graph_conv = DyGraphConv2d(in_channels, in_channels * 2, kernel_size, dilation, conv,\n",
    "                              act, norm, bias, stochastic, epsilon, r)\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels * 2, in_channels, 1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "        )\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.relative_pos = None\n",
    "        self.LPE = None\n",
    "\n",
    "        if relative_pos:\n",
    "            print('using relative_pos')\n",
    "            relative_pos_tensor = torch.from_numpy(np.float32(get_2d_relative_pos_embed(in_channels,\n",
    "                int(n**0.5)))).unsqueeze(0).unsqueeze(1)\n",
    "            relative_pos_tensor = F.interpolate(\n",
    "                    relative_pos_tensor, size=(n, n//(r*r)), mode='bicubic', align_corners=False)\n",
    "            self.relative_pos = nn.Parameter(-relative_pos_tensor.squeeze(1), requires_grad=False)\n",
    "        if LPE:\n",
    "            print('using Learnable Positional Embedding')\n",
    "            LPE_tensor = torch.from_numpy(np.float32(get_2d_sincos_pos_embed(in_channels,\n",
    "                int(n**0.5)))).unsqueeze(0).unsqueeze(1)\n",
    "            LPE_tensor = F.interpolate(\n",
    "                    LPE_tensor, size=(n, n//(r*r)), mode='bilinear', align_corners=False)\n",
    "            self.LPE_tensor = nn.Parameter(-LPE_tensor.squeeze(1), requires_grad=False)\n",
    "\n",
    "    def _get_relative_pos(self, relative_pos, H, W):\n",
    "        if relative_pos is None or H * W == self.n:\n",
    "            return relative_pos\n",
    "        else:\n",
    "            N = H * W\n",
    "            N_reduced = N // (self.r * self.r)\n",
    "            return F.interpolate(relative_pos.unsqueeze(0), size=(N, N_reduced), mode=\"bicubic\").squeeze(0)\n",
    "\n",
    "    def _get_LPE(self, LPE, H, W):\n",
    "        if LPE is None or H * W == self.n:\n",
    "            return LPE\n",
    "        else:\n",
    "            N = H * W\n",
    "            N_reduced = N // (self.r * self.r)\n",
    "            return F.interpolate(LPE.unsqueeze(0), size=(N, N_reduced), mode=\"bicubic\").squeeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _tmp = x\n",
    "        x = self.fc1(x)\n",
    "        B, C, H, W = x.shape\n",
    "        relative_pos = self._get_relative_pos(self.relative_pos, H, W)\n",
    "        LPE = self._get_LPE(self.LPE, H, W)\n",
    "        # x = self.graph_conv(x, relative_pos)\n",
    "        x = self.graph_conv(x, LPE)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop_path(x) + _tmp\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2022.06.17-Changed for building ViG model\n",
    "#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential as Seq\n",
    "\n",
    "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from timm.models.helpers import load_pretrained\n",
    "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "from timm.models.registry import register_model\n",
    "\n",
    "# from gcn_lib import Grapher, act_layer\n",
    "\n",
    "\n",
    "def _cfg(url='', **kwargs):\n",
    "    return {\n",
    "        'url': url,\n",
    "        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': None,\n",
    "        'crop_pct': .9, 'interpolation': 'bicubic',\n",
    "        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n",
    "        'first_conv': 'patch_embed.proj', 'classifier': 'head',\n",
    "        **kwargs\n",
    "    }\n",
    "\n",
    "\n",
    "default_cfgs = {\n",
    "    'vig_224_gelu': _cfg(\n",
    "        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n",
    "    ),\n",
    "    'vig_b_224_gelu': _cfg(\n",
    "        crop_pct=0.95, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act='relu', drop_path=0.0):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_features, hidden_features, 1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(hidden_features),\n",
    "        )\n",
    "        self.act = act_layer(act)\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_features, out_features, 1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(out_features),\n",
    "        )\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop_path(x) + shortcut\n",
    "        return x#.reshape(B, C, N, 1)\n",
    "\n",
    "\n",
    "class Stem(nn.Module):\n",
    "    \"\"\" Image to Visual Embedding\n",
    "    Overlap: https://arxiv.org/pdf/2106.13797.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, in_dim=3, out_dim=768, act='relu'):\n",
    "        super().__init__()        \n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, out_dim//2, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_dim//2),\n",
    "            act_layer(act),\n",
    "            nn.Conv2d(out_dim//2, out_dim, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "            act_layer(act),\n",
    "            nn.Conv2d(out_dim, out_dim, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    \"\"\" Convolution-based downsample\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim=3, out_dim=768):\n",
    "        super().__init__()        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, out_dim, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DeepGCN(torch.nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(DeepGCN, self).__init__()\n",
    "        print(opt)\n",
    "        k = opt.k\n",
    "        act = opt.act\n",
    "        norm = opt.norm\n",
    "        bias = opt.bias\n",
    "        epsilon = opt.epsilon\n",
    "        stochastic = opt.use_stochastic\n",
    "        conv = opt.conv\n",
    "        emb_dims = opt.emb_dims\n",
    "        drop_path = opt.drop_path\n",
    "        \n",
    "        blocks = opt.blocks\n",
    "        self.n_blocks = sum(blocks)\n",
    "        channels = opt.channels\n",
    "        reduce_ratios = [4, 2, 1, 1]\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path, self.n_blocks)]  # stochastic depth decay rule \n",
    "        num_knn = [int(x.item()) for x in torch.linspace(k, k, self.n_blocks)]  # number of knn's k\n",
    "        max_dilation = 49 // max(num_knn)\n",
    "        \n",
    "        self.stem = Stem(out_dim=channels[0], act=act)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, channels[0], 224//4, 224//4))\n",
    "        HW = 224 // 4 * 224 // 4\n",
    "\n",
    "        self.backbone = nn.ModuleList([])\n",
    "        idx = 0\n",
    "        for i in range(len(blocks)):\n",
    "            if i > 0:\n",
    "                self.backbone.append(Downsample(channels[i-1], channels[i]))\n",
    "                HW = HW // 4\n",
    "            for j in range(blocks[i]):\n",
    "                self.backbone += [\n",
    "                    Seq(Grapher(channels[i], num_knn[idx], min(idx // 4 + 1, max_dilation), conv, act, norm,\n",
    "                                    bias, stochastic, epsilon, reduce_ratios[i], n=HW, drop_path=dpr[idx],\n",
    "                                    relative_pos=True, LPE=False),\n",
    "                          FFN(channels[i], channels[i] * 4, act=act, drop_path=dpr[idx])\n",
    "                         )]\n",
    "                idx += 1\n",
    "        self.backbone = Seq(*self.backbone)\n",
    "\n",
    "        self.prediction = Seq(nn.Conv2d(channels[-1], 1024, 1, bias=True),\n",
    "                              nn.BatchNorm2d(1024),\n",
    "                              act_layer(act),\n",
    "                              nn.Dropout(opt.dropout),\n",
    "                              nn.Conv2d(1024, opt.n_classes, 1, bias=True))\n",
    "        self.model_init()\n",
    "\n",
    "    def model_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "                m.weight.requires_grad = True\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "                    m.bias.requires_grad = True\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.stem(inputs) + self.pos_embed\n",
    "        B, C, H, W = x.shape\n",
    "        for i in range(len(self.backbone)):\n",
    "            x = self.backbone[i](x)\n",
    "\n",
    "        x = F.adaptive_avg_pool2d(x, 1)\n",
    "        return self.prediction(x).squeeze(-1).squeeze(-1)\n",
    "\n",
    "class DeepGCN_LPE(torch.nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(DeepGCN_LPE, self).__init__()\n",
    "        print(opt)\n",
    "        k = opt.k\n",
    "        act = opt.act\n",
    "        norm = opt.norm\n",
    "        bias = opt.bias\n",
    "        epsilon = opt.epsilon\n",
    "        stochastic = opt.use_stochastic\n",
    "        conv = opt.conv\n",
    "        emb_dims = opt.emb_dims\n",
    "        drop_path = opt.drop_path\n",
    "        \n",
    "        blocks = opt.blocks\n",
    "        self.n_blocks = sum(blocks)\n",
    "        channels = opt.channels\n",
    "        reduce_ratios = [4, 2, 1, 1]\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path, self.n_blocks)]  # stochastic depth decay rule \n",
    "        num_knn = [int(x.item()) for x in torch.linspace(k, k, self.n_blocks)]  # number of knn's k\n",
    "        max_dilation = 49 // max(num_knn)\n",
    "        \n",
    "        self.stem = Stem(out_dim=channels[0], act=act)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, channels[0], 224//4, 224//4))\n",
    "        HW = 224 // 4 * 224 // 4\n",
    "\n",
    "        self.backbone = nn.ModuleList([])\n",
    "        idx = 0\n",
    "        for i in range(len(blocks)):\n",
    "            if i > 0:\n",
    "                self.backbone.append(Downsample(channels[i-1], channels[i]))\n",
    "                HW = HW // 4\n",
    "            for j in range(blocks[i]):\n",
    "                self.backbone += [\n",
    "                    Seq(Grapher(channels[i], num_knn[idx], min(idx // 4 + 1, max_dilation), conv, act, norm,\n",
    "                                    bias, stochastic, epsilon, reduce_ratios[i], n=HW, drop_path=dpr[idx],\n",
    "                                    relative_pos=False, LPE=True),\n",
    "                          FFN(channels[i], channels[i] * 4, act=act, drop_path=dpr[idx])\n",
    "                         )]\n",
    "                idx += 1\n",
    "        self.backbone = Seq(*self.backbone)\n",
    "\n",
    "        self.prediction = Seq(nn.Conv2d(channels[-1], 1024, 1, bias=True),\n",
    "                              nn.BatchNorm2d(1024),\n",
    "                              act_layer(act),\n",
    "                              nn.Dropout(opt.dropout),\n",
    "                              nn.Conv2d(1024, opt.n_classes, 1, bias=True))\n",
    "        self.model_init()\n",
    "\n",
    "    def model_init(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "                m.weight.requires_grad = True\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "                    m.bias.requires_grad = True\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.stem(inputs) + self.pos_embed\n",
    "        B, C, H, W = x.shape\n",
    "        for i in range(len(self.backbone)):\n",
    "            x = self.backbone[i](x)\n",
    "\n",
    "        x = F.adaptive_avg_pool2d(x, 1)\n",
    "        return self.prediction(x).squeeze(-1).squeeze(-1)\n",
    "\n",
    "\n",
    "\n",
    "@register_model\n",
    "def pvig_ti_224(pretrained=False, **kwargs):\n",
    "    class OptInit:\n",
    "        def __init__(self, num_classes=1000, drop_path_rate=0.0, **kwargs):\n",
    "            self.k = 9 # neighbor num (default:9)\n",
    "            self.conv = 'mr' # graph conv layer {edge, mr, sage, gin}\n",
    "            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n",
    "            self.norm = 'batch' # batch or instance normalization {batch, instance}\n",
    "            self.bias = True # bias of conv layer True or False\n",
    "            self.dropout = 0.0 # dropout rate\n",
    "            self.use_dilation = True # use dilated knn or not\n",
    "            self.epsilon = 0.2 # stochastic epsilon for gcn\n",
    "            self.use_stochastic = False # stochastic for gcn, True or False\n",
    "            self.drop_path = drop_path_rate\n",
    "            self.blocks = [2,2,6,2] # number of basic blocks in the backbone\n",
    "            self.channels = [48, 96, 240, 384] # number of channels of deep features\n",
    "            self.n_classes = num_classes # Dimension of out_channels\n",
    "            self.emb_dims = 1024 # Dimension of embeddings\n",
    "\n",
    "    opt = OptInit(**kwargs)\n",
    "    model = DeepGCN(opt)\n",
    "    model.default_cfg = default_cfgs['vig_224_gelu']\n",
    "    return model\n",
    "\n",
    "\n",
    "@register_model\n",
    "def pvig_s_224(pretrained=False, **kwargs):\n",
    "    class OptInit:\n",
    "        def __init__(self, num_classes=1000, drop_path_rate=0.0, **kwargs):\n",
    "            self.k = 9 # neighbor num (default:9)\n",
    "            self.conv = 'mr' # graph conv layer {edge, mr, sage, gin}\n",
    "            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n",
    "            self.norm = 'batch' # batch or instance normalization {batch, instance}\n",
    "            self.bias = True # bias of conv layer True or False\n",
    "            self.dropout = 0.0 # dropout rate\n",
    "            self.use_dilation = True # use dilated knn or not\n",
    "            self.epsilon = 0.2 # stochastic epsilon for gcn\n",
    "            self.use_stochastic = False # stochastic for gcn, True or False\n",
    "            self.drop_path = drop_path_rate\n",
    "            self.blocks = [2,2,6,2] # number of basic blocks in the backbone\n",
    "            self.channels = [80, 160, 400, 640] # number of channels of deep features\n",
    "            self.n_classes = num_classes # Dimension of out_channels\n",
    "            self.emb_dims = 1024 # Dimension of embeddings\n",
    "\n",
    "    opt = OptInit(**kwargs)\n",
    "    model = DeepGCN(opt)\n",
    "    model.default_cfg = default_cfgs['vig_224_gelu']\n",
    "    return model\n",
    "\n",
    "\n",
    "@register_model\n",
    "def pvig_m_224(pretrained=False, **kwargs):\n",
    "    class OptInit:\n",
    "        def __init__(self, num_classes=1000, drop_path_rate=0.0, **kwargs):\n",
    "            self.k = 9 # neighbor num (default:9)\n",
    "            self.conv = 'mr' # graph conv layer {edge, mr, sage, gin}\n",
    "            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n",
    "            self.norm = 'batch' # batch or instance normalization {batch, instance}\n",
    "            self.bias = True # bias of conv layer True or False\n",
    "            self.dropout = 0.0 # dropout rate\n",
    "            self.use_dilation = True # use dilated knn or not\n",
    "            self.epsilon = 0.2 # stochastic epsilon for gcn\n",
    "            self.use_stochastic = False # stochastic for gcn, True or False\n",
    "            self.drop_path = drop_path_rate\n",
    "            self.blocks = [2,2,16,2] # number of basic blocks in the backbone\n",
    "            self.channels = [96, 192, 384, 768] # number of channels of deep features\n",
    "            self.n_classes = num_classes # Dimension of out_channels\n",
    "            self.emb_dims = 1024 # Dimension of embeddings\n",
    "\n",
    "    opt = OptInit(**kwargs)\n",
    "    model = DeepGCN(opt)\n",
    "    model.default_cfg = default_cfgs['vig_224_gelu']\n",
    "    return model\n",
    "\n",
    "\n",
    "@register_model\n",
    "def pvig_b_224(pretrained=False, **kwargs):\n",
    "    class OptInit:\n",
    "        def __init__(self, num_classes=1000, drop_path_rate=0.0, **kwargs):\n",
    "            self.k = 9 # neighbor num (default:9)\n",
    "            self.conv = 'mr' # graph conv layer {edge, mr, sage, gin}\n",
    "            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n",
    "            self.norm = 'batch' # batch or instance normalization {batch, instance}\n",
    "            self.bias = True # bias of conv layer True or False\n",
    "            self.dropout = 0.0 # dropout rate\n",
    "            self.use_dilation = True # use dilated knn or not\n",
    "            self.epsilon = 0.2 # stochastic epsilon for gcn\n",
    "            self.use_stochastic = False # stochastic for gcn, True or False\n",
    "            self.drop_path = drop_path_rate\n",
    "            self.blocks = [2,2,18,2] # number of basic blocks in the backbone\n",
    "            self.channels = [128, 256, 512, 1024] # number of channels of deep features\n",
    "            self.n_classes = num_classes # Dimension of out_channels\n",
    "            self.emb_dims = 1024 # Dimension of embeddings\n",
    "\n",
    "    opt = OptInit(**kwargs)\n",
    "    model = DeepGCN(opt)\n",
    "    model.default_cfg = default_cfgs['vig_b_224_gelu']\n",
    "    return model\n",
    "\n",
    "@register_model\n",
    "def pvig_ti_224_LPE(pretrained=False, **kwargs):\n",
    "    class OptInit:\n",
    "        def __init__(self, num_classes=1000, drop_path_rate=0.0, **kwargs):\n",
    "            self.k = 9 # neighbor num (default:9)\n",
    "            self.conv = 'gin' # graph conv layer {edge, mr, sage, gin}\n",
    "            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n",
    "            self.norm = 'batch' # batch or instance normalization {batch, instance}\n",
    "            self.bias = True # bias of conv layer True or False\n",
    "            self.dropout = 0.0 # dropout rate\n",
    "            self.use_dilation = True # use dilated knn or not\n",
    "            self.epsilon = 0.2 # stochastic epsilon for gcn\n",
    "            self.use_stochastic = False # stochastic for gcn, True or False\n",
    "            self.drop_path = drop_path_rate\n",
    "            self.blocks = [2,2,6,2] # number of basic blocks in the backbone\n",
    "            self.channels = [48, 96, 240, 384] # number of channels of deep features\n",
    "            self.n_classes = num_classes # Dimension of out_channels\n",
    "            self.emb_dims = 1024 # Dimension of embeddings\n",
    "\n",
    "    opt = OptInit(**kwargs)\n",
    "    model = DeepGCN_LPE(opt)\n",
    "    model.default_cfg = default_cfgs['vig_224_gelu']\n",
    "    return model\n",
    "\n",
    "\n",
    "@register_model\n",
    "def pvig_s_224_LPE(pretrained=False, **kwargs):\n",
    "    class OptInit:\n",
    "        def __init__(self, num_classes=1000, drop_path_rate=0.0, **kwargs):\n",
    "            self.k = 9 # neighbor num (default:9)\n",
    "            self.conv = 'gin' # graph conv layer {edge, mr, sage, gin}\n",
    "            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n",
    "            self.norm = 'batch' # batch or instance normalization {batch, instance}\n",
    "            self.bias = True # bias of conv layer True or False\n",
    "            self.dropout = 0.0 # dropout rate\n",
    "            self.use_dilation = True # use dilated knn or not\n",
    "            self.epsilon = 0.2 # stochastic epsilon for gcn\n",
    "            self.use_stochastic = False # stochastic for gcn, True or False\n",
    "            self.drop_path = drop_path_rate\n",
    "            self.blocks = [2,2,6,2] # number of basic blocks in the backbone\n",
    "            self.channels = [80, 160, 400, 640] # number of channels of deep features\n",
    "            self.n_classes = num_classes # Dimension of out_channels\n",
    "            self.emb_dims = 1024 # Dimension of embeddings\n",
    "\n",
    "    opt = OptInit(**kwargs)\n",
    "    model = DeepGCN_LPE(opt)\n",
    "    model.default_cfg = default_cfgs['vig_224_gelu']\n",
    "    return model\n",
    "\n",
    "\n",
    "@register_model\n",
    "def pvig_m_224_LPE(pretrained=False, **kwargs):\n",
    "    class OptInit:\n",
    "        def __init__(self, num_classes=1000, drop_path_rate=0.0, **kwargs):\n",
    "            self.k = 9 # neighbor num (default:9)\n",
    "            self.conv = 'gin' # graph conv layer {edge, mr, sage, gin}\n",
    "            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n",
    "            self.norm = 'batch' # batch or instance normalization {batch, instance}\n",
    "            self.bias = True # bias of conv layer True or False\n",
    "            self.dropout = 0.0 # dropout rate\n",
    "            self.use_dilation = True # use dilated knn or not\n",
    "            self.epsilon = 0.2 # stochastic epsilon for gcn\n",
    "            self.use_stochastic = False # stochastic for gcn, True or False\n",
    "            self.drop_path = drop_path_rate\n",
    "            self.blocks = [2,2,16,2] # number of basic blocks in the backbone\n",
    "            self.channels = [96, 192, 384, 768] # number of channels of deep features\n",
    "            self.n_classes = num_classes # Dimension of out_channels\n",
    "            self.emb_dims = 1024 # Dimension of embeddings\n",
    "\n",
    "    opt = OptInit(**kwargs)\n",
    "    model = DeepGCN_LPE(opt)\n",
    "    model.default_cfg = default_cfgs['vig_224_gelu']\n",
    "    return model\n",
    "\n",
    "\n",
    "@register_model\n",
    "def pvig_b_224_LPE(pretrained=False, **kwargs):\n",
    "    class OptInit:\n",
    "        def __init__(self, num_classes=1000, drop_path_rate=0.0, **kwargs):\n",
    "            self.k = 9 # neighbor num (default:9)\n",
    "            self.conv = 'gin' # graph conv layer {edge, mr, sage, gin}\n",
    "            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n",
    "            self.norm = 'batch' # batch or instance normalization {batch, instance}\n",
    "            self.bias = True # bias of conv layer True or False\n",
    "            self.dropout = 0.0 # dropout rate\n",
    "            self.use_dilation = True # use dilated knn or not\n",
    "            self.epsilon = 0.2 # stochastic epsilon for gcn\n",
    "            self.use_stochastic = False # stochastic for gcn, True or False\n",
    "            self.drop_path = drop_path_rate\n",
    "            self.blocks = [2,2,18,2] # number of basic blocks in the backbone\n",
    "            self.channels = [128, 256, 512, 1024] # number of channels of deep features\n",
    "            self.n_classes = num_classes # Dimension of out_channels\n",
    "            self.emb_dims = 1024 # Dimension of embeddings\n",
    "\n",
    "    opt = OptInit(**kwargs)\n",
    "    model = DeepGCN_LPE(opt)\n",
    "    model.default_cfg = default_cfgs['vig_b_224_gelu']\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터별 등급 분별 (특상 L, 상 M, 보통 S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5943 2388\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# 학습을 위해 데이터 증가(augmentation) 및 일반화(normalization)\n",
    "# 검증을 위한 일반화\n",
    "# from email.mime import image\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "data_dir = '../../Apple_Quality/dataset/Apple_sweetlevel_Jeonbuk/'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "print(len(image_datasets['train']), len(image_datasets['val']))\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "              for x in ['train', 'val']}\n",
    "            \n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train','val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "print(len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # torch.utils.data.Subset 모듈로 나누기 (20% validation)\n",
    "# val_size = int(0.2 * len(Arisu_datasets))\n",
    "# train_set = torch.utils.data.Subset(Arisu_datasets, range(val_size, len(Arisu_datasets)))\n",
    "# val_set = torch.utils.data.Subset(Arisu_datasets, range(val_size))\n",
    "\n",
    "# print(len(train_set), len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(train_set, batch_size=4,\n",
    "#                                              shuffle=True, num_workers=0, drop_last=True)\n",
    "# val_loader = torch.utils.data.DataLoader(val_set, batch_size=4, shuffle=True, num_workers=0, drop_last=True)\n",
    "# # dataloaders['test'] = torch.utils.data.DataLoader(train_set, batch_size=16,\n",
    "#                                             #  shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.pvig_ti_224.<locals>.OptInit object at 0x7f3cf45ded30>\n",
      "using relative_pos\n",
      "using relative_pos\n",
      "using relative_pos\n",
      "using relative_pos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62902/3354495458.py:74: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  omega = np.arange(embed_dim // 2, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using relative_pos\n",
      "using relative_pos\n",
      "using relative_pos\n",
      "using relative_pos\n",
      "using relative_pos\n",
      "using relative_pos\n",
      "using relative_pos\n",
      "using relative_pos\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = pvig_ti_224()\n",
    "model.prediction[4] = Conv2d(1024, len(class_names), kernel_size=(1,1), stride=(1,1))\n",
    "# print(model)\n",
    "model = model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.95)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sweet_B_grade', 'Sweet_A_grade', 'Sweet_C_grade', 'Sweet_B_grade', 'Sweet_B_grade', 'Sweet_C_grade', 'Sweet_C_grade', 'Sweet_A_grade']\n"
     ]
    }
   ],
   "source": [
    "# transform 된 배치 이미지 시각화\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # 갱신이 될 때까지 잠시 기다립니다.\n",
    "\n",
    "\n",
    "# 학습 데이터의 배치를 얻습니다.\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# 배치로부터 격자 형태의 이미지를 만듭니다.\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out)\n",
    "print([class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# writer = SummaryWriter()\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    # model = model.to(device)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        \n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "        # print(f\"time per 1 epoch: {time.time() - since:.2f}\")\n",
    "\n",
    "        # 각 에폭(epoch)은 학습 단계와 검증 단계를 갖습니다.\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                # model.load_state_dict(model_state_dict)\n",
    "                model.train()  # 모델을 학습 모드로 설정\n",
    "            else:\n",
    "                # model.load_state_dict(model_state_dict)\n",
    "                model.eval()   # 모델을 평가 모드로 설정\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # 데이터를 반복\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # 매개변수 경사도를 0으로 설정\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 순전파\n",
    "                # 학습 시에만 연산 기록을 추적\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # 학습 단계인 경우 역전파 + 최적화\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # 통계\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            # writer.add_scalar(\"Loss/train\", epoch_loss, epoch)\n",
    "            # writer.add_scalar(\"Acc/train\", epoch_acc, epoch)\n",
    "            # wandb.log({'train_acc': epoch_acc, 'train_loss' : epoch_loss})\n",
    "\n",
    "            # 모델을 깊은 복사(deep copy)함\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                print(\"Update best acc! :\", best_acc)\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "       \n",
    "        print()\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "    # wandb.log({'test_acc': best_acc})\n",
    "    \n",
    "\n",
    "    # 가장 나은 모델 가중치를 불러옴\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.0665 Acc: 0.4949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [10:45<3:24:28, 645.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2170 Acc: 0.4334\n",
      "Update best acc! : tensor(0.4334, device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.0475 Acc: 0.5043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [21:31<3:13:44, 645.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2510 Acc: 0.4573\n",
      "Update best acc! : tensor(0.4573, device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.0323 Acc: 0.5038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [32:16<3:02:50, 645.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2026 Acc: 0.4334\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.0333 Acc: 0.5014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [43:01<2:52:03, 645.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1361 Acc: 0.4393\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.0315 Acc: 0.5050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [53:43<2:41:01, 644.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2648 Acc: 0.4280\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.0284 Acc: 0.5050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [1:04:27<2:30:17, 644.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2019 Acc: 0.4506\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.0225 Acc: 0.5058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [1:15:06<2:19:12, 642.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2203 Acc: 0.4535\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.0169 Acc: 0.5065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [1:25:46<2:08:20, 641.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2374 Acc: 0.4468\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.0156 Acc: 0.5134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [1:36:29<1:57:40, 641.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2603 Acc: 0.4477\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.0076 Acc: 0.5189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [1:47:11<1:47:00, 642.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1996 Acc: 0.4523\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.9991 Acc: 0.5206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [1:57:55<1:36:22, 642.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1923 Acc: 0.4493\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.9967 Acc: 0.5164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [2:08:38<1:25:41, 642.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1779 Acc: 0.4514\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.9941 Acc: 0.5275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [2:19:21<1:14:59, 642.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2071 Acc: 0.4644\n",
      "Update best acc! : tensor(0.4644, device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.9938 Acc: 0.5221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [2:30:06<1:04:20, 643.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2430 Acc: 0.4594\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.9907 Acc: 0.5233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [2:40:45<53:31, 642.31s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2054 Acc: 0.4569\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.9898 Acc: 0.5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [2:51:31<42:53, 643.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1969 Acc: 0.4460\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.9942 Acc: 0.5220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [3:02:15<32:10, 643.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1995 Acc: 0.4615\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.9946 Acc: 0.5262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [3:12:59<21:27, 643.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2102 Acc: 0.4497\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.9888 Acc: 0.5241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [3:23:43<10:43, 643.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1929 Acc: 0.4560\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.9905 Acc: 0.5179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [3:34:27<00:00, 643.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2046 Acc: 0.4535\n",
      "\n",
      "Training complete in 214m 28s\n",
      "Best val Acc: 0.464405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeepGCN(\n",
       "  (stem): Stem(\n",
       "    (convs): Sequential(\n",
       "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU()\n",
       "      (3): Conv2d(24, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): GELU()\n",
       "      (6): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (backbone): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Downsample(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Downsample(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(480, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(480, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (8): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(480, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(480, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (10): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(480, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (11): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(240, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(480, 480, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(480, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (12): Downsample(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(240, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (14): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (prediction): Sequential(\n",
       "    (0): Conv2d(384, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): GELU()\n",
       "    (3): Dropout(p=0.0, inplace=False)\n",
       "    (4): Conv2d(1024, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.pvig_s_224.<locals>.OptInit object at 0x7f3ced7048e0>\n",
      "using relative_pos\n",
      "using relative_pos\n",
      "using relative_pos\n",
      "using relative_pos\n",
      "using relative_pos\n",
      "using relative_pos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62902/3354495458.py:74: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  omega = np.arange(embed_dim // 2, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using relative_pos\n",
      "using relative_pos\n",
      "using relative_pos\n",
      "using relative_pos\n",
      "using relative_pos\n",
      "using relative_pos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.2484 Acc: 0.4488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [05:04<1:36:29, 304.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1406 Acc: 0.4481\n",
      "Update best acc! : tensor(0.4481, device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.0874 Acc: 0.4829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [10:10<1:31:34, 305.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1253 Acc: 0.4602\n",
      "Update best acc! : tensor(0.4602, device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.0641 Acc: 0.4886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [15:14<1:26:17, 304.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0830 Acc: 0.4577\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.0570 Acc: 0.4962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [20:16<1:21:02, 303.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2529 Acc: 0.4644\n",
      "Update best acc! : tensor(0.4644, device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.0437 Acc: 0.4934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [25:19<1:15:50, 303.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2960 Acc: 0.4481\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.0377 Acc: 0.5014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [30:22<1:10:47, 303.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1397 Acc: 0.4569\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.0359 Acc: 0.5014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [35:24<1:05:38, 302.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2245 Acc: 0.4493\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.0311 Acc: 0.4954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [40:26<1:00:32, 302.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.3718 Acc: 0.4598\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.0233 Acc: 0.5073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [45:30<55:33, 303.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1625 Acc: 0.4682\n",
      "Update best acc! : tensor(0.4682, device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.0179 Acc: 0.5090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [50:34<50:31, 303.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2150 Acc: 0.4631\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.9964 Acc: 0.5181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [55:37<45:27, 303.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2901 Acc: 0.4573\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.9953 Acc: 0.5238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [1:00:42<40:29, 303.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1977 Acc: 0.4665\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.9873 Acc: 0.5272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [1:05:45<35:25, 303.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2313 Acc: 0.4682\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.9933 Acc: 0.5236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [1:10:47<30:18, 303.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2356 Acc: 0.4577\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.9831 Acc: 0.5181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [1:15:50<25:15, 303.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2683 Acc: 0.4606\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.9788 Acc: 0.5241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [1:20:55<20:14, 303.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2135 Acc: 0.4627\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.9818 Acc: 0.5374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [1:25:58<15:10, 303.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2039 Acc: 0.4598\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.9821 Acc: 0.5273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [1:31:06<10:09, 304.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2316 Acc: 0.4669\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.9881 Acc: 0.5273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [1:36:11<05:04, 304.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2966 Acc: 0.4619\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.9815 Acc: 0.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [1:41:12<00:00, 303.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2633 Acc: 0.4606\n",
      "\n",
      "Training complete in 101m 13s\n",
      "Best val Acc: 0.468174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeepGCN(\n",
       "  (stem): Stem(\n",
       "    (convs): Sequential(\n",
       "      (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): GELU()\n",
       "      (3): Conv2d(40, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (4): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): GELU()\n",
       "      (6): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (backbone): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Downsample(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(160, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(640, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Downsample(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(160, 400, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(800, 800, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(800, 400, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(800, 800, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(800, 400, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (8): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(800, 800, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(800, 400, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(800, 800, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(800, 400, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (10): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(800, 800, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(800, 400, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (11): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(800, 800, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(800, 400, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(400, 1600, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(1600, 400, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (12): Downsample(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(400, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (14): Sequential(\n",
       "      (0): Grapher(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (graph_conv): DyGraphConv2d(\n",
       "          (gconv): MRConv2d(\n",
       "            (nn): BasicConv(\n",
       "              (0): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
       "              (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): GELU()\n",
       "            )\n",
       "          )\n",
       "          (dilated_knn_graph): DenseDilatedKnnGraph(\n",
       "            (_dilated): DenseDilated()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): FFN(\n",
       "        (fc1): Sequential(\n",
       "          (0): Conv2d(640, 2560, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act): GELU()\n",
       "        (fc2): Sequential(\n",
       "          (0): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (prediction): Sequential(\n",
       "    (0): Conv2d(640, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): GELU()\n",
       "    (3): Dropout(p=0.0, inplace=False)\n",
       "    (4): Conv2d(1024, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "model = pvig_s_224()\n",
    "model.prediction[4] = Conv2d(1024, len(class_names), kernel_size=(1,1), stride=(1,1))\n",
    "# print(model)\n",
    "model = model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.95)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
    "                                             shuffle=True, num_workers=2)\n",
    "              for x in ['train', 'val']}\n",
    "# summary(model, (3, 224, 224))\n",
    "train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.pvig_m_224_LPE.<locals>.OptInit object at 0x7f7a43cbc0d0>\n",
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85686/3354495458.py:74: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  omega = np.arange(embed_dim // 2, dtype=np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n",
      "using Learnable Positional Embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 1.2340 Acc: 0.4410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [11:50<3:44:52, 710.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2559 Acc: 0.4221\n",
      "Update best acc! : tensor(0.4221, device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 1.0923 Acc: 0.4871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [23:40<3:33:02, 710.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1087 Acc: 0.4104\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 1.0610 Acc: 0.4858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [35:29<3:21:09, 709.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1091 Acc: 0.4493\n",
      "Update best acc! : tensor(0.4493, device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 1.0557 Acc: 0.4918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [47:19<3:09:18, 709.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1081 Acc: 0.4389\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 1.0540 Acc: 0.4895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [59:09<2:57:24, 709.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1112 Acc: 0.4472\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 1.0454 Acc: 0.4935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [1:10:59<2:45:37, 709.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0987 Acc: 0.4527\n",
      "Update best acc! : tensor(0.4527, device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 1.0386 Acc: 0.4962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [1:22:47<2:33:43, 709.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1308 Acc: 0.4497\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 1.0320 Acc: 0.5031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [1:34:38<2:21:58, 709.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1246 Acc: 0.4648\n",
      "Update best acc! : tensor(0.4648, device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 1.0280 Acc: 0.4999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [1:46:26<2:10:02, 709.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2877 Acc: 0.4343\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 1.0231 Acc: 0.5008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [1:58:15<1:58:11, 709.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1199 Acc: 0.4606\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.9961 Acc: 0.5225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [2:10:05<1:46:24, 709.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0989 Acc: 0.4535\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.9907 Acc: 0.5280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [2:21:57<1:34:41, 710.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1698 Acc: 0.4523\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.9944 Acc: 0.5245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [2:33:45<1:22:47, 709.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.2655 Acc: 0.4485\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.9867 Acc: 0.5262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [2:45:34<1:10:56, 709.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1752 Acc: 0.4502\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.9896 Acc: 0.5275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [2:57:22<59:04, 708.93s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1736 Acc: 0.4527\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [2:58:53<59:37, 715.54s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/andrew/jihoon_python/pretrained_GNN/code/11_pretrainedViG_sweetlevel.ipynb 셀 19\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B168.131.153.57/home/andrew/jihoon_python/pretrained_GNN/code/11_pretrainedViG_sweetlevel.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m dataloaders \u001b[39m=\u001b[39m {x: torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(image_datasets[x], batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B168.131.153.57/home/andrew/jihoon_python/pretrained_GNN/code/11_pretrainedViG_sweetlevel.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m                                              shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B168.131.153.57/home/andrew/jihoon_python/pretrained_GNN/code/11_pretrainedViG_sweetlevel.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m               \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m]}\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B168.131.153.57/home/andrew/jihoon_python/pretrained_GNN/code/11_pretrainedViG_sweetlevel.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# summary(model, (3, 224, 224))\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B168.131.153.57/home/andrew/jihoon_python/pretrained_GNN/code/11_pretrainedViG_sweetlevel.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m train_model(model, criterion, optimizer, exp_lr_scheduler,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B168.131.153.57/home/andrew/jihoon_python/pretrained_GNN/code/11_pretrainedViG_sweetlevel.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m                        num_epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n",
      "\u001b[1;32m/home/andrew/jihoon_python/pretrained_GNN/code/11_pretrainedViG_sweetlevel.ipynb 셀 19\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B168.131.153.57/home/andrew/jihoon_python/pretrained_GNN/code/11_pretrainedViG_sweetlevel.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m running_corrects \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B168.131.153.57/home/andrew/jihoon_python/pretrained_GNN/code/11_pretrainedViG_sweetlevel.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# 데이터를 반복\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B168.131.153.57/home/andrew/jihoon_python/pretrained_GNN/code/11_pretrainedViG_sweetlevel.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mfor\u001b[39;00m inputs, labels \u001b[39min\u001b[39;00m dataloaders[phase]:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B168.131.153.57/home/andrew/jihoon_python/pretrained_GNN/code/11_pretrainedViG_sweetlevel.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B168.131.153.57/home/andrew/jihoon_python/pretrained_GNN/code/11_pretrainedViG_sweetlevel.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/geo/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/geo/lib/python3.9/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/geo/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/geo/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/geo/lib/python3.9/site-packages/torchvision/datasets/folder.py:230\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39m    index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    229\u001b[0m path, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples[index]\n\u001b[0;32m--> 230\u001b[0m sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloader(path)\n\u001b[1;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m     sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(sample)\n",
      "File \u001b[0;32m~/anaconda3/envs/geo/lib/python3.9/site-packages/torchvision/datasets/folder.py:269\u001b[0m, in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[39mreturn\u001b[39;00m accimage_loader(path)\n\u001b[1;32m    268\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m     \u001b[39mreturn\u001b[39;00m pil_loader(path)\n",
      "File \u001b[0;32m~/anaconda3/envs/geo/lib/python3.9/site-packages/torchvision/datasets/folder.py:249\u001b[0m, in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    248\u001b[0m     img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(f)\n\u001b[0;32m--> 249\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mconvert(\u001b[39m\"\u001b[39;49m\u001b[39mRGB\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/geo/lib/python3.9/site-packages/PIL/Image.py:901\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert\u001b[39m(\n\u001b[1;32m    857\u001b[0m     \u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, matrix\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dither\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, palette\u001b[39m=\u001b[39mPalette\u001b[39m.\u001b[39mWEB, colors\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m\n\u001b[1;32m    858\u001b[0m ):\n\u001b[1;32m    859\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \u001b[39m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[39m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    903\u001b[0m     has_transparency \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtransparency\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    904\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mode \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    905\u001b[0m         \u001b[39m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/geo/lib/python3.9/site-packages/PIL/ImageFile.py:257\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m    252\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mimage file is truncated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(b)\u001b[39m}\u001b[39;00m\u001b[39m bytes not processed)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m         )\n\u001b[1;32m    256\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[0;32m--> 257\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    259\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "model = pvig_m_224_LPE(pretrained=True)\n",
    "model.prediction[4] = Conv2d(1024, len(class_names), kernel_size=(1,1), stride=(1,1))\n",
    "# print(model)\n",
    "model = model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.95)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "              for x in ['train', 'val']}\n",
    "# summary(model, (3, 224, 224))\n",
    "train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "model = pvig_b_224_LPE(pretrained=True)\n",
    "model.prediction[4] = Conv2d(1024, len(class_names), kernel_size=(1,1), stride=(1,1))\n",
    "# print(model)\n",
    "model = model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.95)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "              for x in ['train', 'val']}\n",
    "# summary(model, (3, 224, 224))\n",
    "train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
    "                       num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('geo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8616a860257f6741c1b5f4a77ff6ccf51a19eff03d81799217c8f280496915f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
